{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "MLFLow Relates Libraries",
   "id": "f93a58bf65fe013a"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-13T04:14:07.901240Z",
     "start_time": "2025-03-13T04:14:07.883447Z"
    }
   },
   "source": [
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import model.preprocessors as pp\n",
    "import model.config as config\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 138
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "By default mlflow tracking is set to mlruns directory",
   "id": "df97b149aaccd058"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T04:14:07.946469Z",
     "start_time": "2025-03-13T04:14:07.935228Z"
    }
   },
   "cell_type": "code",
   "source": "mlflow.tracking.get_tracking_uri()",
   "id": "28ce1e443854a274",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:///Users/cipri/Documents/GitHub/IntroMLOps/mlruns'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 139
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Loan Prediction (Example)",
   "id": "a809364f68b00334"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T04:14:07.951284Z",
     "start_time": "2025-03-13T04:14:07.948651Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "216ae99e9a5d1889",
   "outputs": [],
   "execution_count": 139
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T04:14:08.004180Z",
     "start_time": "2025-03-13T04:14:07.958502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df = pd.read_csv('model/train.csv')\n",
    "test_df = pd.read_csv('model/test.csv')\n",
    "print(\"Train Size\", train_df.shape)\n",
    "print(\"Test Size\", test_df.shape)"
   ],
   "id": "7495dd23f467266a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size (614, 13)\n",
      "Test Size (362, 12)\n"
     ]
    }
   ],
   "execution_count": 140
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T04:14:08.034640Z",
     "start_time": "2025-03-13T04:14:08.009444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = train_df.drop([config.TARGET], axis=1)\n",
    "y = train_df[config.TARGET].map({\"N\": 0, \"Y\": 1})\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=20)"
   ],
   "id": "adbd7e5d0503e321",
   "outputs": [],
   "execution_count": 141
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T04:14:08.053080Z",
     "start_time": "2025-03-13T04:14:08.036604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_model_pipeline(classifier):\n",
    "    loan_pipe = Pipeline(\n",
    "    [\n",
    "        (\"Numerical Imputer\", pp.NumericalImputer(variables=config.NUMERICAL_FEATURES)),\n",
    "        (\n",
    "            \"Categorical Imputer\",\n",
    "            pp.CategoricalImputer(variables=config.CATEGORICAL_FEATURES),\n",
    "        ),\n",
    "        (\n",
    "            \"Temporal Features\",\n",
    "            pp.TemporalVariableEstimator(\n",
    "                variables=config.TEMPORAL_FEATURES,\n",
    "                reference_variable=config.TEMPORAL_ADDITION,\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"Categorical Encoder\",\n",
    "            pp.CategoricalEncoder(variables=config.FEATURES_TO_ENCODE),\n",
    "        ),\n",
    "        (\"Log Transform\", pp.LogTransformation(variables=config.LOG_FEATURES)),\n",
    "        (\"Drop Features\", pp.DropFeatures(variables_to_drop=config.DROP_FEATURES)),\n",
    "        (\"Scaler Transform\", MinMaxScaler()),\n",
    "        (\"Linear Model\",classifier),\n",
    "            ]\n",
    "    )\n",
    "    return loan_pipe\n",
    "\n",
    "def model_metrics(actual, pred):\n",
    "    accuracy = metrics.accuracy_score(actual, pred)\n",
    "    f1 = metrics.f1_score(actual, pred, pos_label=1)\n",
    "    fpr, tpr, thresholds1 = metrics.roc_curve(actual, pred)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    return {\"accuracy\": accuracy,\n",
    "            \"f1\": f1,\n",
    "            \"auc\": auc}\n",
    "\n"
   ],
   "id": "180a7519e1a8a65b",
   "outputs": [],
   "execution_count": 142
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train Model",
   "id": "e21dd5c068699882"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T04:14:08.530782Z",
     "start_time": "2025-03-13T04:14:08.054721Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rf_params = {\n",
    "    \"n_estimators\": 300,  # Number of trees in the forest\n",
    "    \"criterion\": \"gini\",  # \"gini\" for Gini Impurity, \"entropy\" for Information Gain\n",
    "    \"max_depth\": None,  # Maximum depth of the tree (None = expand fully)\n",
    "    \"min_samples_split\": 2,  # Minimum number of samples to split a node\n",
    "    \"min_samples_leaf\": 1,  # Minimum number of samples per leaf node\n",
    "    \"max_features\": \"sqrt\",  # Number of features to consider for best split\n",
    "    \"bootstrap\": True,  # Whether to bootstrap samples\n",
    "    \"oob_score\": False,  # Whether to use out-of-bag samples for validation\n",
    "    \"n_jobs\": -1,  # Use all processors for parallel processing\n",
    "    \"random_state\": 42,  # Ensures reproducibility\n",
    "}\n",
    "\n",
    "pipeline_model= create_model_pipeline(RandomForestClassifier(**rf_params))\n",
    "pipeline_model.fit(X_train[config.FEATURES], y_train)\n",
    "y_pred = pipeline_model.predict(X_test[config.FEATURES])\n",
    "\n",
    "\n",
    "metrics_model = model_metrics(y_test, y_pred)\n",
    "input_example = pd.read_json(\"model/input_example.json\")[config.FEATURES].dropna()\n",
    "pipeline_model.predict (input_example)"
   ],
   "id": "85e2613b80d5313b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 143
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Model Tracking: \n",
    "\n",
    "MLflow Tracking is an API and user interface component that records data about machine learning experiments and lets you query it\n",
    "\n",
    "You can use the tracking UI to visualize, compare, and search runs. Additionally, it lets you download metadata or artifacts for runs, which you can input for analysis in other tools. MLflow logs information about runs in an mlruns directory; in order to view the data, you can run the MLflow UI one directory above the mlruns folder\n",
    "\n",
    "* Add Experiment and Log Model"
   ],
   "id": "a019708e5ba581df"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T04:14:08.544836Z",
     "start_time": "2025-03-13T04:14:08.532404Z"
    }
   },
   "cell_type": "code",
   "source": "mlflow.set_experiment(\"Loan Prediction\")",
   "id": "414b66f1d9f3e447",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///Users/cipri/Documents/GitHub/IntroMLOps/mlruns/578337268861345417', creation_time=1741762737026, experiment_id='578337268861345417', last_update_time=1741762737026, lifecycle_stage='active', name='Loan Prediction', tags={}>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 144
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T04:14:08.549968Z",
     "start_time": "2025-03-13T04:14:08.546117Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SklearnWrapper(mlflow.pyfunc.PythonModel):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def predict(self, context: mlflow.pyfunc.PythonModelContext, model_input: pd.DataFrame) -> np.ndarray:\n",
    "        return self.model.predict(model_input)"
   ],
   "id": "12ac29671dbc0971",
   "outputs": [],
   "execution_count": 145
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T04:14:15.024662Z",
     "start_time": "2025-03-13T04:14:08.551101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with mlflow.start_run(run_name=\"RandomForestClassifier\") as run:\n",
    "        # Run id\n",
    "        run_id = run.info.run_id\n",
    "        mlflow.set_tag(\"run_id\", run_id)\n",
    "\n",
    "        y_pred = pipeline_model.predict(X_test[config.FEATURES])\n",
    "        metrics_model = model_metrics(y_test, y_pred)\n",
    "        signature = infer_signature(input_example, pipeline_model.predict(input_example))\n",
    "        model_wrapped = SklearnWrapper(pipeline_model)\n",
    "        \n",
    "        mlflow.log_metrics(metrics=metrics_model)\n",
    "        mlflow.log_params(params=rf_params)\n",
    "        \n",
    "        # log the sklearn model \n",
    "        model_info = mlflow.sklearn.log_model(\n",
    "            sk_model=pipeline_model,\n",
    "            signature=signature,\n",
    "            artifact_path=\"model\",\n",
    "            input_example=input_example,\n",
    "            registered_model_name=\"tracking-RandomForestClassifier\"\n",
    "        )\n",
    "        \n",
    "        # just to overwrite the existing directory\n",
    "        model_path = \"RandomForestClassifier\"\n",
    "        if os.path.exists(model_path):\n",
    "            shutil.rmtree(model_path)\n",
    "        \n",
    "        # generalized manner: user a wrapper on top of the pipeline\n",
    "        # this only saves the model locally\n",
    "        signature = infer_signature(input_example, model_wrapped.predict(None, input_example))\n",
    "        mlflow.pyfunc.save_model(path=model_path, python_model=SklearnWrapper(pipeline_model), signature=signature, input_example=input_example)"
   ],
   "id": "76c6917629d73420",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cipri/Documents/GitHub/IntroMLOps/.venv/lib/python3.9/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Registered model 'tracking-RandomForestClassifier' already exists. Creating a new version of this model...\n",
      "Created version '20' of model 'tracking-RandomForestClassifier'.\n",
      "/Users/cipri/Documents/GitHub/IntroMLOps/.venv/lib/python3.9/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "2025/03/12 22:14:12 INFO mlflow.pyfunc: Validating input example against model signature\n"
     ]
    }
   ],
   "execution_count": 146
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Inference with logged model",
   "id": "e6deab6b6d1fa238"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "25cad039f52c7d59"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T04:14:15.133778Z",
     "start_time": "2025-03-13T04:14:15.026062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loaded_model = mlflow.pyfunc.load_model(model_info.model_uri)\n",
    "loaded_model.predict(input_example)"
   ],
   "id": "389403d482237fc2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 147
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 📌 MLflow Model UI\n",
    "\n",
    "```bash\n",
    "mlflow ui"
   ],
   "id": "376a2fdeea7101be"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 📌 MLflow Model Serve\n",
    "\n",
    "make sure you have installed pyenv, if needed run:\n",
    "\n",
    "```bash\n",
    "pip install pyenv\n"
   ],
   "id": "a9a8e7b324ee382d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "```bash\n",
    "mlflow models serve -m model_uri -p port_id"
   ],
   "id": "305cef95210c39"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 📌 MLflow Model Inference: Correct JSON Request Format\n",
    "\n",
    "When making predictions using an MLflow model, ensure the request format matches the **expected input schema**.\n",
    "\n",
    "## ✅ **Correct `curl` Request (Using `dataframe_records`)**\n",
    "Use the **`dataframe_records`** key to send structured data:\n",
    "\n",
    "```bash\n",
    "curl http://127.0.0.1:8000/invocations \\\n",
    "     -H \"Content-Type: application/json\" \\\n",
    "     --data '{\n",
    "         \"dataframe_records\": [\n",
    "             {\n",
    "                 \"Gender\": \"Male\",\n",
    "                 \"Married\": \"Yes\",\n",
    "                 \"Dependents\": \"0\",\n",
    "                 \"Education\": \"Graduate\",\n",
    "                 \"Self_Employed\": \"No\",\n",
    "                 \"ApplicantIncome\": 5720,\n",
    "                 \"CoapplicantIncome\": 0,\n",
    "                 \"LoanAmount\": 110,\n",
    "                 \"Loan_Amount_Term\": 360,\n",
    "                 \"Credit_History\": 1,\n",
    "                 \"Property_Area\": \"Urban\"\n",
    "             }\n",
    "         ]\n",
    "     }'"
   ],
   "id": "e4b800a84c62abfa"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
